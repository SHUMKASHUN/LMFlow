Search.setIndex({"docnames": ["about/authors", "about/changelog", "about/index", "api/_autosummary/lmflow.args", "autoapi/index", "autoapi/lmflow/args/index", "autoapi/lmflow/datasets/dataset/index", "autoapi/lmflow/datasets/index", "autoapi/lmflow/index", "autoapi/lmflow/models/auto_model/index", "autoapi/lmflow/models/base_model/index", "autoapi/lmflow/models/decoder_model/index", "autoapi/lmflow/models/hf_decoder_model/index", "autoapi/lmflow/models/index", "autoapi/lmflow/models/interfaces/index", "autoapi/lmflow/models/interfaces/tunable/index", "autoapi/lmflow/models/regression_model/index", "autoapi/lmflow/models/text_regression_model/index", "autoapi/lmflow/pipeline/auto_pipeline/index", "autoapi/lmflow/pipeline/base_aligner/index", "autoapi/lmflow/pipeline/base_pipeline/index", "autoapi/lmflow/pipeline/base_tuner/index", "autoapi/lmflow/pipeline/evaluator/index", "autoapi/lmflow/pipeline/finetuner/index", "autoapi/lmflow/pipeline/index", "autoapi/lmflow/pipeline/inferencer/index", "autoapi/lmflow/pipeline/raft_aligner/index", "autoapi/lmflow/pipeline/utils/index", "autoapi/lmflow/pipeline/utils/raft_trainer/index", "autoapi/lmflow/utils/data_utils/index", "autoapi/lmflow/utils/index", "autoapi/lmflow/version/index", "documentation/data", "documentation/index", "documentation/infer", "documentation/model", "documentation/tuning", "examples/DATASETS", "examples/index", "examples/medical_finetune", "index"], "filenames": ["about/authors.md", "about/changelog.md", "about/index.md", "api/_autosummary/lmflow.args.rst", "autoapi/index.rst", "autoapi/lmflow/args/index.rst", "autoapi/lmflow/datasets/dataset/index.rst", "autoapi/lmflow/datasets/index.rst", "autoapi/lmflow/index.rst", "autoapi/lmflow/models/auto_model/index.rst", "autoapi/lmflow/models/base_model/index.rst", "autoapi/lmflow/models/decoder_model/index.rst", "autoapi/lmflow/models/hf_decoder_model/index.rst", "autoapi/lmflow/models/index.rst", "autoapi/lmflow/models/interfaces/index.rst", "autoapi/lmflow/models/interfaces/tunable/index.rst", "autoapi/lmflow/models/regression_model/index.rst", "autoapi/lmflow/models/text_regression_model/index.rst", "autoapi/lmflow/pipeline/auto_pipeline/index.rst", "autoapi/lmflow/pipeline/base_aligner/index.rst", "autoapi/lmflow/pipeline/base_pipeline/index.rst", "autoapi/lmflow/pipeline/base_tuner/index.rst", "autoapi/lmflow/pipeline/evaluator/index.rst", "autoapi/lmflow/pipeline/finetuner/index.rst", "autoapi/lmflow/pipeline/index.rst", "autoapi/lmflow/pipeline/inferencer/index.rst", "autoapi/lmflow/pipeline/raft_aligner/index.rst", "autoapi/lmflow/pipeline/utils/index.rst", "autoapi/lmflow/pipeline/utils/raft_trainer/index.rst", "autoapi/lmflow/utils/data_utils/index.rst", "autoapi/lmflow/utils/index.rst", "autoapi/lmflow/version/index.rst", "documentation/data.md", "documentation/index.md", "documentation/infer.md", "documentation/model.md", "documentation/tuning.md", "examples/DATASETS.md", "examples/index.md", "examples/medical_finetune.md", "index.md"], "titles": ["Contributors", "Changelog", "About", "lmflow.args", "API Reference", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.args</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.datasets.dataset</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.datasets</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.auto_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.base_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.decoder_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.hf_decoder_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.interfaces</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.interfaces.tunable</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.regression_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.text_regression_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.auto_pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.base_aligner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.base_pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.base_tuner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.evaluator</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.finetuner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.inferencer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.raft_aligner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.utils.raft_trainer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.data_utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.version</span></code>", "Data", "Documentation", "Inference", "Model", "Fine-tuning", "Dataset", "Examples", "Finetune", "LMFlow"], "terms": {"shizh": [0, 40], "diao": [0, 40], "rui": [0, 40], "pan": [0, 40], "hanz": [0, 40], "dong": [0, 40], "ka": 0, "shun": 0, "shum": [0, 40], "jipeng": [0, 40], "zhang": [0, 40], "wei": [0, 40], "xiong": [0, 40], "tong": [0, 40], "The": [1, 5, 6, 7, 11, 12, 18, 22, 23, 25, 26, 28, 29, 37, 40], "first": [1, 28], "public": 1, "task": [1, 12, 28], "tune": [1, 12, 21, 23, 28, 39], "instruct": 1, "user": [1, 37, 40], "defin": [1, 3, 5, 6, 7, 28, 37], "dataset": [1, 3, 4, 5, 8, 12, 17, 19, 21, 22, 23, 25, 26, 28, 29, 38, 39, 40], "A": [1, 6, 11, 12, 17, 19, 21, 26, 28, 29], "simpl": [1, 28], "extens": [1, 40], "api": [1, 40], "develop": 1, "effici": [1, 40], "finetun": [1, 4, 8, 24, 37, 40], "lora": [1, 12, 40], "simplifi": [1, 22, 23, 25, 26, 40], "model": [1, 3, 4, 5, 8, 19, 21, 22, 23, 25, 26, 28, 37, 39, 40], "infer": [1, 12, 22, 25, 37, 40], "framework": 1, "changelog": [2, 40], "version": [2, 3, 4, 5, 8], "0": [2, 8, 25, 26, 28, 31, 40], "1": [2, 4, 5, 6, 8, 28, 31, 37, 39, 40], "mar": 2, "28": [2, 40], "2023": [2, 40], "contributor": [2, 40], "thi": [3, 4, 5, 6, 7, 11, 12, 26, 28, 29, 37, 40], "script": [3, 5, 28, 39], "dataclass": [3, 5], "modelargu": [3, 5, 22, 23, 25, 26, 39], "datasetargu": [3, 5, 6, 22, 23, 25, 26, 39], "contain": [3, 4, 5, 6, 11, 22, 23, 25, 26, 28, 37], "argument": [3, 5, 6, 7, 12, 17, 22, 23, 25, 26, 28, 29, 39], "us": [3, 5, 10, 11, 12, 15, 16, 20, 22, 28, 29, 37, 38, 40], "train": [3, 5, 12, 23, 26, 28, 29, 37, 40], "It": [3, 5, 12, 22, 28, 40], "import": [3, 5, 22, 28, 39, 40], "sever": [3, 5, 12, 28, 29, 37, 38], "modul": 3, "includ": [3, 5, 6, 7, 28, 29, 40], "field": [3, 5, 40], "from": [3, 5, 6, 7, 12, 22, 28, 29, 39, 40], "type": [3, 5, 6, 9, 17, 28, 37], "option": [3, 5, 6, 11, 12, 17, 23, 26, 28], "require_vers": [3, 5], "transform": [3, 5, 12, 28, 39], "util": [3, 4, 5, 8, 24, 26, 40], "model_for_causal_lm_map": [3, 5], "trainingargu": [3, 5, 28], "model_config_class": [3, 5], "i": [3, 5, 12, 19, 21, 22, 26, 28, 37, 40], "assign": [3, 5], "list": [3, 5, 12, 28, 29, 37, 40], "config": [3, 5, 39], "class": [3, 7], "model_typ": [3, 5], "tupl": [3, 5, 28], "extract": [3, 5, 29], "page": [4, 40], "auto": [4, 5], "gener": [4, 5, 12, 16, 22, 26, 28, 29, 38, 40], "document": [4, 28], "lmflow": [4, 39], "interfac": [4, 8, 12, 13], "tunabl": [4, 8, 12, 13, 14, 21], "auto_model": [4, 8, 13], "base_model": [4, 8, 11, 13, 16], "decoder_model": [4, 8, 12, 13], "hf_decoder_model": [4, 8, 13], "regression_model": [4, 8, 13, 17], "text_regression_model": [4, 8, 13], "pipelin": [4, 8, 37, 39, 40], "raft_train": [4, 8, 24, 27], "auto_pipelin": [4, 8, 24, 39], "base_align": [4, 8, 24, 26], "base_pipelin": [4, 8, 19, 21, 22, 24, 25], "base_tun": [4, 8, 23, 24], "evalu": [4, 5, 8, 24, 28, 37, 40], "inferenc": [4, 5, 8, 24, 37], "raft_align": [4, 8, 24], "data_util": [4, 8, 30], "arg": [4, 6, 8, 9, 10, 11, 12, 16, 17, 18, 19, 21, 23, 26, 28, 29, 39], "creat": [4, 6, 10, 11, 15, 16, 20, 22, 28, 40], "sphinx": 4, "autoapi": 4, "sourc": [5, 6, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 28, 29, 31, 37, 40], "decor": 5, "paramet": [5, 6, 12, 17, 22, 23, 25, 26, 28, 29, 40], "can": [5, 12, 28, 37, 40], "configur": 5, "model_name_or_path": 5, "str": [5, 6, 12, 25, 28, 29], "string": [5, 6, 12, 28, 29], "repres": [5, 6, 12], "path": [5, 12, 17, 28, 39], "name": [5, 12, 17, 18, 28, 29], "pretrain": [5, 12, 28, 40], "checkpoint": [5, 28], "weight": [5, 22, 40], "initi": [5, 6, 7, 12, 17, 22, 23, 25, 26, 28, 39], "If": [5, 28, 29, 39, 40], "none": [5, 6, 12, 22, 26, 28, 29], "scratch": 5, "provid": [5, 10, 11, 12, 15, 16, 20, 22, 28, 37, 38, 40], "config_overrid": 5, "default": [5, 6, 12, 28, 29], "set": [5, 12, 28, 29, 37], "overrid": [5, 28], "when": [5, 28], "config_nam": 5, "differ": [5, 6, 7, 12, 28], "tokenizer_nam": 5, "token": [5, 12, 26, 28, 39], "cache_dir": 5, "directori": [5, 12, 22, 28, 37], "where": [5, 37], "download": [5, 37], "huggingfac": [5, 6, 12], "co": 5, "store": 5, "use_fast_token": 5, "bool": [5, 28, 29], "boolean": 5, "indic": [5, 37], "whether": [5, 12, 28], "fast": 5, "back": 5, "librari": [5, 28], "model_revis": 5, "specif": [5, 40], "branch": 5, "tag": [5, 28], "commit": [5, 28], "id": [5, 12], "use_auth_token": 5, "run": [5, 22, 23, 26, 28, 37], "cli": 5, "login": 5, "necessari": [5, 28], "privat": 5, "torch_dtyp": 5, "dtype": [5, 28], "load": [5, 6, 7, 12, 22, 23, 25, 26, 28, 29], "under": [5, 28, 37, 40], "pass": [5, 28, 39, 40], "automat": [5, 9, 18, 28], "deriv": 5, "": [5, 28, 39, 40], "use_ram_optimized_load": 5, "disk": 5, "map": [5, 6, 7, 17, 39], "memori": 5, "enough": 5, "lora_model_path": 5, "arch_typ": 5, "use_lora": 5, "lora_r": 5, "int": [5, 12, 25, 28, 29], "lora_alpha": 5, "lora_dropout": 5, "float": [5, 17, 25, 28], "save_aggregated_lora": 5, "__post_init__": 5, "languag": [5, 12, 22, 23, 28, 40], "dataset_path": 5, "dataset_nam": 5, "valu": [5, 28], "custom": [5, 28, 37], "is_custom_dataset": 5, "data": [5, 17, 22, 23, 26, 28, 29, 37, 40], "fals": [5, 12, 28], "customized_cache_dir": 5, "cach": [5, 28], "dataset_config_nam": 5, "via": 5, "train_fil": 5, "input": [5, 12, 22, 25, 26, 28, 29, 37], "file": [5, 22, 28, 29, 37, 39, 40], "text": [5, 12, 22, 23, 29, 37, 39], "validation_fil": 5, "perplex": 5, "max_train_sampl": 5, "an": [5, 10, 11, 15, 16, 20, 28, 40], "integ": 5, "maximum": [5, 23, 28], "number": [5, 28], "exampl": [5, 11, 28, 29, 37, 40], "debug": 5, "quicker": 5, "truncat": 5, "max_eval_sampl": 5, "stream": 5, "enabl": 5, "mode": [5, 28], "block_siz": 5, "sequenc": [5, 12, 28], "length": [5, 12, 23, 28, 29], "after": [5, 37], "block": [5, 23, 28], "size": [5, 22, 28], "also": [5, 11, 22, 28, 40], "some": [5, 22, 28, 40], "addit": [5, 28], "further": [5, 40], "overwrite_cach": 5, "validation_split_percentag": 5, "preprocessing_num_work": 5, "disable_group_text": 5, "demo_example_in_prompt": 5, "explanation_in_prompt": 5, "keep_linebreak": 5, "prompt_structur": [5, 25], "function": [5, 11, 17, 26, 28, 40], "help": [5, 40], "messag": [5, 28], "each": [5, 28, 37], "hint": 5, "metadata": [5, 28], "inform": [5, 6, 22, 28, 40], "about": [5, 28, 40], "test_fil": 5, "finetunerargu": [5, 23], "base": [5, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 28, 40], "adapt": [5, 12, 28, 40], "evaluatorargu": [5, 22], "local_rank": [5, 26], "For": [5, 28, 37, 40], "distribut": [5, 28], "random_shuffl": [5, 29], "use_wandb": [5, 22], "random_se": 5, "output_dir": [5, 28], "mixed_precis": 5, "choic": [5, 29], "bf16": 5, "fp16": 5, "mix": 5, "precis": 5, "deepspe": [5, 12, 28, 39], "json": [5, 6, 7, 28, 29, 37, 39], "e": [5, 26, 28, 29, 40], "g": [5, 28], "ds_config": [5, 12], "alreadi": [5, 28], "dict": [5, 6, 28], "answer_typ": [5, 22, 29], "evaluate_block_s": 5, "metric": [5, 22, 28], "inferencerargu": [5, 25], "devic": [5, 12, 28], "raftalignerargu": [5, 26], "raft": 5, "align": [5, 19, 26], "output_reward_path": [5, 26], "output_min_length": [5, 26], "output_max_length": [5, 26], "num_raft_iter": 5, "raft_batch_s": 5, "top_reward_percentag": 5, "inference_batch_size_per_devic": 5, "pipeline_argument_map": 5, "autoargu": [5, 39], "choos": [5, 28], "get_pipeline_args_class": [5, 39], "python": [6, 7, 40], "code": [6, 7, 28], "method": [6, 7, 12, 22, 28, 40], "manipul": [6, 7], "backend": [6, 7, 12, 28], "hug": [6, 7, 37], "face": [6, 7], "dictionari": [6, 7, 22, 23, 28], "retriev": [6, 7], "dataset_typ": 6, "text_onli": [6, 17, 37], "text2text": [6, 38], "key_typ": 6, "key_inst": 6, "instanc": [6, 12, 17, 22, 23, 28, 37, 40], "data_arg": [6, 18, 22, 23, 25, 26, 39], "kwarg": [6, 9, 10, 11, 12, 16, 17, 18, 19, 21, 23, 26, 28], "object": [6, 17, 22, 23, 25, 26, 28], "given": [6, 17, 22, 23, 25, 26, 28], "requir": [6, 22, 23, 25, 26, 40], "posit": [6, 12, 17, 23, 26, 40], "keyword": [6, 12, 17, 23, 26, 28], "_check_data_typ": 6, "from_dict": 6, "dict_obj": 6, "return": [6, 12, 18, 22, 23, 25, 26, 28, 29], "format": [6, 38], "key_1": [6, 37], "value_1": [6, 37], "key_2": [6, 37], "2": [6, 26, 37, 39, 40], "value_2": [6, 37], "self": [6, 28], "classmethod": [6, 9, 18], "create_from_dict": 6, "to_dict": 6, "get_backend": 6, "get_backend_dataset": 6, "backend_dataset": 6, "get_data_arg": 6, "get_typ": 6, "internal_vers": 8, "__version__": [8, 31], "get": [9, 17, 26, 28, 39], "correct": 9, "automodel": 9, "get_model": 9, "model_arg": [9, 12, 17, 18, 22, 23, 25, 26, 39], "basemodel": [10, 11, 16, 26], "abc": [10, 11, 15, 16, 20], "helper": [10, 11, 15, 16, 20, 28], "standard": [10, 11, 15, 16, 20], "wai": [10, 11, 15, 16, 20, 28, 37], "inherit": [10, 11, 15, 16, 20, 28], "one": [11, 28, 39], "line": 11, "summari": [11, 28], "program": [11, 29], "termin": 11, "period": 11, "leav": 11, "blank": 11, "rest": 11, "docstr": 11, "should": [11, 28], "overal": [11, 12, 40], "descript": [11, 28], "mai": [11, 28], "brief": 11, "export": 11, "usag": 11, "typic": 11, "foo": 11, "classfoo": 11, "bar": 11, "functionbar": 11, "decodermodel": [11, 12], "call": [12, 28], "hfdecodermodel": [12, 22], "which": [12, 19, 21, 28, 37, 40], "wrapper": [12, 28], "around": 12, "ha": [12, 22, 28, 37], "__init__": 12, "ar": [12, 28, 37, 40], "fine": [12, 28, 33, 40], "take": [12, 22, 26, 28], "tune_strategi": 12, "attent": 12, "mask": 12, "fed": [12, 28], "support": [12, 38], "normal": 12, "allow": [12, 28, 40], "howev": [12, 40], "strategi": 12, "yet": 12, "implement": [12, 28], "conveni": [12, 40], "variou": [12, 28, 37, 40], "nlp": 12, "classif": [12, 28], "question": [12, 26, 37], "answer": [12, 29, 37], "logger": [12, 23, 26, 28], "gpu": [12, 28], "revis": [12, 17], "etc": [12, 17, 28, 40], "configu": 12, "full": [12, 40], "tokenized_dataset": [12, 23, 39], "encod": [12, 22, 37], "union": [12, 28], "perform": [12, 22, 23, 25, 26, 28, 40], "process": [12, 22, 23, 25, 26, 28, 39, 40], "output": [12, 22, 26, 28, 29, 37], "decod": [12, 22, 29, 37], "prompt": [12, 26, 37, 40], "merge_lora_weight": 12, "save": [12, 28, 40], "dir": 12, "save_full_model": 12, "get_max_length": [12, 39], "max": 12, "accept": [12, 17, 28, 37], "term": 12, "get_token": 12, "get_backend_model": 12, "regress": [16, 17], "regressionmodel": [16, 17, 26], "textregressionmodel": 17, "register_regression_funct": 17, "regression_func": 17, "regist": 17, "get_regress": 17, "result": [17, 40], "onli": [17, 28, 37, 39, 40], "its": [18, 28, 40], "pipeline_map": 18, "autopipelin": [18, 39], "design": [18, 40], "get_pipelin": [18, 39], "pipeline_nam": [18, 39], "pipeline_arg": [18, 39], "basetun": [19, 21, 23], "subclass": [19, 21, 28], "basepipelin": [19, 20, 21, 22, 25], "basealign": [19, 26], "_check_if_align": 19, "reward_model": [19, 26], "abstract": [19, 21], "_check_if_tun": 21, "packag": [22, 38, 40], "constructor": 22, "three": [22, 37], "relat": [22, 40], "evaluator_arg": 22, "other": [22, 28, 40], "two": [22, 28], "create_dataload": [22, 25], "test": [22, 28, 37, 40], "loader": 22, "iter": [22, 26, 28], "over": [22, 37], "mini": 22, "batch": [22, 28, 29], "Then": 22, "write": 22, "log": [22, 28], "consol": 22, "bias": 22, "true": [22, 28, 29], "_match": 22, "predicted_answ": 22, "groundtruth": 22, "accuraci": [22, 40], "tunablemodel": [22, 23, 25, 39], "_evaluate_ppl": 22, "finetuner_arg": 23, "group_text": [23, 39], "model_max_length": [23, 39], "group": [23, 28, 39], "togeth": [23, 28], "form": [23, 28], "lm_dataset": [23, 39], "inferencer_arg": 25, "max_new_token": 25, "100": [25, 28], "temperatur": 25, "output_dataset": 25, "raftalign": 26, "aligner_arg": 26, "raft_aligner_arg": 26, "_initialize_train": 26, "training_arg": [26, 28], "trainer": [26, 28], "_load_dataset": 26, "selected_dataset": 26, "prepar": [26, 28, 40], "everi": [26, 28], "_load_input_dataset": 26, "dataload": [26, 28, 29], "torch": [26, 28, 29], "_get_batch_dataset_top": 26, "batch_input": 26, "alpha": 26, "iter_id": 26, "16": 26, "48": 26, "infer_batch_s": 26, "8": [26, 40], "generation_kwarg": 26, "feed": [26, 28], "reward": 26, "_is_native_cpu_amp_avail": 28, "default_callback": 28, "default_progress_callback": 28, "is_sagemaker_mp_post_1_10": 28, "skip_first_batch": 28, "training_args_nam": 28, "bin": 28, "trainer_state_nam": 28, "trainer_st": 28, "optimizer_nam": 28, "optim": 28, "pt": 28, "scheduler_nam": 28, "schedul": 28, "scaler_nam": 28, "scaler": 28, "rafttrain": 28, "modeling_util": 28, "pretrainedmodel": 28, "nn": 28, "data_col": 28, "datacol": 28, "train_dataset": 28, "eval_dataset": 28, "tokenization_utils_bas": 28, "pretrainedtokenizerbas": 28, "model_init": 28, "callabl": 28, "compute_metr": 28, "trainer_util": 28, "evalpredict": 28, "callback": 28, "trainer_callback": 28, "trainercallback": 28, "lr_schedul": 28, "lambdalr": 28, "preprocess_logits_for_metr": 28, "tensor": 28, "featur": 28, "complet": [28, 40], "eval": 28, "loop": 28, "pytorch": 28, "predict": 28, "must": [28, 39, 40], "tip": 28, "work": 28, "you": [28, 40], "still": [28, 40], "your": [28, 38], "own": [28, 37], "long": [28, 37], "thei": [28, 37], "same": 28, "tweak": 28, "Will": 28, "basic": 28, "tmp_trainer": 28, "current": [28, 37], "element": [28, 40], "default_data_col": 28, "datacollatorwithpad": 28, "otherwis": 28, "iterabledataset": 28, "column": 28, "forward": 28, "remov": 28, "note": [28, 40], "random": [28, 29], "fashion": 28, "either": 28, "intern": 28, "ident": 28, "all": [28, 40], "manual": 28, "seed": [28, 29], "epoch": 28, "have": [28, 37, 40], "set_epoch": 28, "rng": 28, "prepend": 28, "kei": [28, 37], "preprocess": 28, "pad": 28, "along": 28, "make": [28, 40], "easier": 28, "rerun": 28, "interrupt": 28, "reus": 28, "instanti": 28, "start": 28, "new": [28, 40], "zero": 28, "singl": [28, 37], "optuna": 28, "rai": 28, "sigopt": 28, "trial": 28, "abl": 28, "architectur": 28, "accord": 28, "hyper": 28, "layer": 28, "count": 28, "inner": 28, "dropout": 28, "probabl": 28, "comput": 28, "add": 28, "those": 28, "detail": [28, 38], "here": 28, "want": 28, "remove_callback": 28, "adamw": 28, "get_linear_schedule_with_warmup": 28, "control": 28, "logit": 28, "right": 28, "befor": [28, 40], "them": [28, 40], "step": 28, "label": 28, "onc": 28, "desir": 28, "modif": 28, "made": 28, "reflect": 28, "receiv": 28, "second": 28, "doe": [28, 40], "alwai": 28, "point": 28, "core": 28, "model_wrap": 28, "most": [28, 37], "extern": 28, "case": 28, "more": [28, 40], "wrap": 28, "origin": 28, "again": 28, "distributeddataparallel": 28, "hasn": 28, "t": 28, "been": 28, "is_model_parallel": 28, "switch": 28, "parallel": 28, "mean": 28, "split": 28, "place_model_on_devic": 28, "place": 28, "overridden": 28, "is_in_train": 28, "while": [28, 40], "add_callback": 28, "In": 28, "member": 28, "pop_callback": 28, "found": [28, 40], "error": 28, "rais": 28, "pop": 28, "_move_model_to_devic": 28, "_set_signature_columns_if_need": 28, "_remove_unused_column": 28, "_get_collator_with_removed_column": 28, "collat": 28, "unus": 28, "_get_train_sampl": 28, "sampler": 28, "get_train_dataload": 28, "__len__": 28, "inject": 28, "behavior": 28, "_get_eval_sampl": 28, "get_eval_dataload": 28, "get_test_dataload": 28, "test_dataset": 28, "create_optimizer_and_schedul": 28, "num_training_step": 28, "setup": 28, "learn": [28, 40], "rate": 28, "we": [28, 37, 38, 39, 40], "reason": 28, "well": [28, 40], "someth": 28, "els": [28, 39], "init": 28, "through": 28, "create_optim": 28, "create_schedul": 28, "static": 28, "get_optimizer_cls_and_kwarg": 28, "ani": [28, 40], "session": 28, "up": 28, "do": [28, 40], "num_exampl": 28, "sampl": [28, 37], "access": [28, 40], "exist": 28, "estim": 28, "best": 28, "_hp_search_setup": 28, "hp": 28, "search": [28, 40], "_report_to_hp_search": 28, "_tune_save_checkpoint": 28, "call_model_init": 28, "torch_jit_model_ev": 28, "ipex_optimize_model": 28, "float32": 28, "_wrap_model": 28, "resume_from_checkpoint": 28, "ignore_keys_for_ev": 28, "is_first_tim": 28, "main": [28, 39, 40], "entri": 28, "local": 28, "previou": 28, "equal": 28, "last": 28, "present": 28, "resum": 28, "state": 28, "hyperparamet": 28, "ignor": 28, "gather": 28, "dure": 28, "hide": 28, "deprec": 28, "_one_train": 28, "batch_siz": [28, 29], "_inner_training_loop": 28, "serv": [28, 40], "time": 28, "updat": 28, "_get_output_dir": 28, "_load_from_checkpoint": 28, "_load_best_model": 28, "_issue_warnings_after_load": 28, "load_result": 28, "_maybe_log_save_evalu": 28, "tr_loss": 28, "_load_rng_stat": 28, "_save_checkpoint": 28, "_load_optimizer_and_schedul": 28, "hyperparameter_search": 28, "hp_space": 28, "compute_object": 28, "n_trial": 28, "20": 28, "direct": [28, 40], "minim": 28, "hpsearchbackend": 28, "hp_name": 28, "bestrun": 28, "launch": 28, "quantiti": 28, "determin": 28, "loss": 28, "sum": 28, "warn": 28, "To": [28, 37, 40], "need": [28, 40], "reiniti": 28, "incompat": 28, "so": [28, 40], "space": 28, "default_hp_space_optuna": 28, "default_hp_space_rai": 28, "default_hp_space_sigopt": 28, "depend": 28, "maxim": [28, 40], "default_compute_object": 28, "greater": 28, "lower": 28, "pick": 28, "valid": 28, "training_util": 28, "instal": 28, "create_studi": 28, "see": 28, "http": [28, 40], "readthedoc": 28, "io": [28, 40], "en": 28, "stabl": 28, "refer": [28, 38, 40], "studi": 28, "html": 28, "doc": 28, "latest": 28, "api_doc": 28, "execut": 28, "app": 28, "com": [28, 40], "endpoint": 28, "experi": 28, "run_summari": 28, "watch": 28, "_prepare_input": 28, "nest": 28, "convert": [28, 29], "handl": 28, "potenti": 28, "compute_loss_context_manag": 28, "context": 28, "manag": 28, "autocast_smart_context_manag": 28, "cache_en": 28, "appropri": 28, "autocast": 28, "situat": 28, "training_step": 28, "target": [28, 40], "unpack": 28, "being": 28, "expect": 28, "check": 28, "compute_loss": 28, "return_output": 28, "how": [28, 38], "By": [28, 40], "is_local_process_zero": 28, "machin": [28, 40], "is_world_process_zero": 28, "global": 28, "go": 28, "save_model": 28, "_internal_cal": 28, "reload": 28, "from_pretrain": 28, "_save_tpu": 28, "_save": 28, "state_dict": 28, "store_flo": 28, "_sorted_checkpoint": 28, "checkpoint_prefix": 28, "prefix_checkpoint_dir": 28, "use_mtim": 28, "_rotate_checkpoint": 28, "ignore_kei": 28, "metric_key_prefix": 28, "respons": [28, 29, 40], "wish": 28, "lst": 28, "prefix": 28, "bleu": 28, "eval_bleu": 28, "come": 28, "predictionoutput": 28, "like": [28, 40], "test_bleu": 28, "becaus": 28, "re": 28, "dynam": 28, "concaten": 28, "arrai": 28, "index": [28, 40], "namedtupl": 28, "follow": [28, 37, 40], "np": 28, "ndarrai": 28, "label_id": 28, "evaluation_loop": 28, "prediction_loss_onli": 28, "evalloopoutput": 28, "share": 28, "both": [28, 40], "without": 28, "_nested_gath": 28, "numpi": [28, 29], "_pad_across_process": 28, "pad_index": 28, "recurs": 28, "safe": 28, "prediction_step": 28, "floating_point_op": 28, "oper": 28, "backward": 28, "anoth": 28, "init_git_repo": 28, "at_init": 28, "git": [28, 40], "repo": 28, "hub_model_id": 28, "overwrite_output_dir": 28, "might": 28, "wipe": 28, "out": [28, 40], "create_model_card": 28, "licens": 28, "model_nam": 28, "finetuned_from": 28, "dataset_tag": 28, "dataset_arg": 28, "draft": 28, "card": 28, "avail": [28, 37, 40], "applic": [28, 40], "hub": 28, "One": 28, "identifi": 28, "_push_from_checkpoint": 28, "checkpoint_fold": 28, "push_to_hub": 28, "commit_messag": 28, "end": 28, "upload": 28, "push": 28, "finish": 28, "url": [28, 40], "repositori": [28, 40], "track": 28, "progress": 28, "prediction_loop": 28, "_gather_and_numpifi": 28, "_add_sm_patterns_to_gitignor": 28, "sagemak": 28, "pattern": 28, "gitignor": 28, "set_random_se": 29, "cuda": 29, "load_data": 29, "file_nam": 29, "len": [29, 39], "batchliz": 29, "shuffl": 29, "answer_extract": 29, "funtion": 29, "plain": 29, "b": 29, "c": 29, "d": 29, "mutipl": 29, "qa": 29, "cd": 37, "sh": 37, "strongli": 37, "encourag": 37, "sinc": 37, "appli": [37, 40], "engin": 37, "techniqu": [37, 40], "As": 37, "below": [37, 40], "our": [37, 38, 39, 40], "specifi": 37, "path_to_dataset": 37, "data_1": 37, "data_2": 37, "another_data": 37, "shall": [37, 40], "four": 37, "key_3": 37, "3": [37, 40], "key_4": 37, "4": [37, 40], "value_3": 37, "correspond": 37, "interpret": 37, "common": [37, 40], "raw": 37, "Its": [37, 40], "sample_text_1": 37, "sample_text_2": 37, "sample_text_3": 37, "example_dataset": 37, "train_50": 37, "abov": 37, "mostli": 37, "pair": 37, "sample_input_1": 37, "sample_output_1": 37, "sample_input_2": 37, "sample_output_2": 37, "sample_input_3": 37, "sample_output_3": 37, "test_13": 37, "show": 38, "problem": 38, "textonli": 38, "sy": 39, "hfargumentpars": 39, "tunable_model": 39, "def": 39, "pars": 39, "pipelineargu": 39, "parser": 39, "argv": 39, "endswith": 39, "let": 39, "parse_json_fil": 39, "json_fil": 39, "o": 39, "abspath": 39, "parse_args_into_dataclass": 39, "todo": 39, "done": 39, "main_process_first": 39, "desc": 39, "tuned_model": 39, "toolbox": 40, "larg": 40, "friendli": 40, "speedi": 40, "reliabl": 40, "entir": 40, "commun": 40, "backbon": 40, "llama": 40, "galactica": 40, "gpt": 40, "light": 40, "extrem": 40, "few": 40, "33b": 40, "25mb": 40, "storag": 40, "orient": 40, "compar": 40, "chatgpt": 40, "7b": 40, "open": 40, "whole": 40, "remark": 40, "achiev": 40, "foundat": 40, "expans": 40, "demonstr": 40, "except": 40, "capac": 40, "attain": 40, "human": 40, "intellig": 40, "surpass": 40, "convent": 40, "despit": 40, "grow": 40, "cater": 40, "maintain": 40, "ai": 40, "compet": 40, "pleas": 40, "introduc": 40, "lightweight": 40, "toolkit": 40, "thoughtfulli": 40, "easili": 40, "scalabl": 40, "tool": 40, "publicli": 40, "effect": 40, "thoroughli": 40, "github": 40, "goal": 40, "enhanc": 40, "profici": 40, "particular": 40, "medicin": 40, "mathemat": 40, "acquir": 40, "domain": 40, "better": 40, "subject": 40, "matter": 40, "medic": 40, "gain": 40, "knowledg": 40, "emphas": 40, "signific": 40, "pubmedqa": 40, "medmcqa": 40, "observ": 40, "improv": 40, "medqa": 40, "usml": 40, "averag": 40, "60": 40, "50": 40, "expert": 40, "78": 40, "87": 40, "90": 40, "85": 40, "instructgpt": 40, "175b": 40, "73": 40, "46": 40, "44": 40, "54": 40, "63": 40, "9": 40, "57": 40, "7": 40, "55": 40, "5": 40, "27": 40, "24": 40, "18": 40, "43": 40, "30": 40, "25": 40, "75": 40, "49": 40, "56": 40, "74": 40, "51": 40, "58": 40, "moreov": 40, "mmlu": 40, "verifi": 40, "robust": 40, "anatomi": 40, "clinic": 40, "colleg": 40, "biologi": 40, "genet": 40, "profession": 40, "39": 40, "40": 40, "32": 40, "36": 40, "30b": 40, "26": 40, "23": 40, "120b": 40, "59": 40, "68": 40, "6": 40, "opt": 40, "21": 40, "35": 40, "bloom": 40, "176b": 40, "37": 40, "29": 40, "gopher": 40, "280b": 40, "67": 40, "70": 40, "69": 40, "64": 40, "gpt3": 40, "72": 40, "61": 40, "65": 40, "66": 40, "natur": 40, "command": 40, "neg": 40, "constraint": 40, "commonli": 40, "abil": 40, "multipl": 40, "unseen": 40, "teach": 40, "understand": 40, "incorpor": 40, "cue": 40, "relev": 40, "hand": 40, "power": 40, "wide": 40, "area": 40, "approach": 40, "unlock": 40, "level": 40, "product": 40, "rang": 40, "jsonl": 40, "clone": 40, "optimalscal": 40, "conda": 40, "n": 40, "y": 40, "activ": 40, "mpi4pi": 40, "pip": 40, "readm": 40, "misc": 40, "author": 40, "kashun": 40, "titl": 40, "year": 40, "publish": 40, "journal": 40, "howpublish": 40, "aim": 40, "streamlin": 40, "intend": 40, "li": 40, "sole": 40, "guarante": 40, "legal": 40, "compon": 40, "awar": 40, "assum": 40, "risk": 40, "liabil": 40, "associ": 40, "obtain": 40, "commerci": 40, "technic": 40, "advic": 40, "held": 40, "indirect": 40, "special": 40, "incident": 40, "consequenti": 40, "damag": 40, "improp": 40, "crucial": 40, "highlight": 40, "probabilist": 40, "directli": 40, "therefor": 40, "seek": 40, "reli": 40, "outcom": 40, "account": 40, "relianc": 40, "submit": 40, "issu": 40}, "objects": {"": [[8, 0, 0, "-", "lmflow"]], "lmflow": [[8, 1, 1, "", "__version__"], [5, 0, 0, "-", "args"], [7, 0, 0, "-", "datasets"], [8, 1, 1, "", "internal_version"], [13, 0, 0, "-", "models"], [24, 0, 0, "-", "pipeline"], [30, 0, 0, "-", "utils"], [31, 0, 0, "-", "version"]], "lmflow.args": [[5, 2, 1, "", "AutoArguments"], [5, 2, 1, "", "DatasetArguments"], [5, 2, 1, "", "EvaluatorArguments"], [5, 2, 1, "", "FinetunerArguments"], [5, 2, 1, "", "InferencerArguments"], [5, 1, 1, "", "MODEL_CONFIG_CLASSES"], [5, 1, 1, "", "MODEL_TYPES"], [5, 2, 1, "", "ModelArguments"], [5, 1, 1, "", "PIPELINE_ARGUMENT_MAPPING"], [5, 2, 1, "", "RaftAlignerArguments"]], "lmflow.args.AutoArguments": [[5, 3, 1, "", "get_pipeline_args_class"]], "lmflow.args.DatasetArguments": [[5, 3, 1, "", "__post_init__"], [5, 4, 1, "", "block_size"], [5, 4, 1, "", "customized_cache_dir"], [5, 4, 1, "", "dataset_config_name"], [5, 4, 1, "", "dataset_name"], [5, 4, 1, "", "dataset_path"], [5, 4, 1, "", "disable_group_texts"], [5, 4, 1, "", "is_custom_dataset"], [5, 4, 1, "", "keep_linebreaks"], [5, 4, 1, "", "max_eval_samples"], [5, 4, 1, "", "max_train_samples"], [5, 4, 1, "", "overwrite_cache"], [5, 4, 1, "", "preprocessing_num_workers"], [5, 4, 1, "", "streaming"], [5, 4, 1, "", "test_file"], [5, 4, 1, "", "train_file"], [5, 4, 1, "", "validation_file"], [5, 4, 1, "", "validation_split_percentage"]], "lmflow.args.EvaluatorArguments": [[5, 4, 1, "", "answer_type"], [5, 4, 1, "", "deepspeed"], [5, 4, 1, "", "evaluate_block_size"], [5, 4, 1, "", "local_rank"], [5, 4, 1, "", "metric"], [5, 4, 1, "", "mixed_precision"], [5, 4, 1, "", "output_dir"], [5, 4, 1, "", "prompt_structure"], [5, 4, 1, "", "random_seed"], [5, 4, 1, "", "random_shuffle"], [5, 4, 1, "", "use_wandb"]], "lmflow.args.InferencerArguments": [[5, 4, 1, "", "deepspeed"], [5, 4, 1, "", "device"], [5, 4, 1, "", "local_rank"], [5, 4, 1, "", "mixed_precision"], [5, 4, 1, "", "random_seed"]], "lmflow.args.ModelArguments": [[5, 3, 1, "", "__post_init__"], [5, 4, 1, "", "arch_type"], [5, 4, 1, "", "cache_dir"], [5, 4, 1, "", "config_name"], [5, 4, 1, "", "config_overrides"], [5, 4, 1, "", "lora_alpha"], [5, 4, 1, "", "lora_dropout"], [5, 4, 1, "", "lora_model_path"], [5, 4, 1, "", "lora_r"], [5, 4, 1, "", "model_name_or_path"], [5, 4, 1, "", "model_revision"], [5, 4, 1, "", "model_type"], [5, 4, 1, "", "save_aggregated_lora"], [5, 4, 1, "", "tokenizer_name"], [5, 4, 1, "", "torch_dtype"], [5, 4, 1, "", "use_auth_token"], [5, 4, 1, "", "use_fast_tokenizer"], [5, 4, 1, "", "use_lora"], [5, 4, 1, "", "use_ram_optimized_load"]], "lmflow.args.RaftAlignerArguments": [[5, 4, 1, "", "inference_batch_size_per_device"], [5, 4, 1, "", "num_raft_iteration"], [5, 4, 1, "", "output_max_length"], [5, 4, 1, "", "output_min_length"], [5, 4, 1, "", "output_reward_path"], [5, 4, 1, "", "raft_batch_size"], [5, 4, 1, "", "top_reward_percentage"]], "lmflow.datasets": [[6, 0, 0, "-", "dataset"]], "lmflow.datasets.dataset": [[6, 1, 1, "", "DATASET_TYPES"], [6, 2, 1, "", "Dataset"], [6, 1, 1, "", "KEY_INSTANCES"], [6, 1, 1, "", "KEY_TYPE"]], "lmflow.datasets.dataset.Dataset": [[6, 3, 1, "", "_check_data_type"], [6, 3, 1, "", "create_from_dict"], [6, 3, 1, "", "from_dict"], [6, 3, 1, "", "get_backend"], [6, 3, 1, "", "get_backend_dataset"], [6, 3, 1, "", "get_data_args"], [6, 3, 1, "", "get_type"], [6, 3, 1, "", "map"], [6, 3, 1, "", "to_dict"]], "lmflow.models": [[9, 0, 0, "-", "auto_model"], [10, 0, 0, "-", "base_model"], [11, 0, 0, "-", "decoder_model"], [12, 0, 0, "-", "hf_decoder_model"], [14, 0, 0, "-", "interfaces"], [16, 0, 0, "-", "regression_model"], [17, 0, 0, "-", "text_regression_model"]], "lmflow.models.auto_model": [[9, 2, 1, "", "AutoModel"]], "lmflow.models.auto_model.AutoModel": [[9, 3, 1, "", "get_model"]], "lmflow.models.base_model": [[10, 2, 1, "", "BaseModel"]], "lmflow.models.decoder_model": [[11, 2, 1, "", "DecoderModel"]], "lmflow.models.hf_decoder_model": [[12, 2, 1, "", "HFDecoderModel"], [12, 1, 1, "", "logger"]], "lmflow.models.hf_decoder_model.HFDecoderModel": [[12, 3, 1, "", "decode"], [12, 3, 1, "", "encode"], [12, 3, 1, "", "get_backend_model"], [12, 3, 1, "", "get_max_length"], [12, 3, 1, "", "get_tokenizer"], [12, 3, 1, "", "inference"], [12, 3, 1, "", "merge_lora_weights"], [12, 3, 1, "", "save"], [12, 3, 1, "", "tokenize"]], "lmflow.models.interfaces": [[15, 0, 0, "-", "tunable"]], "lmflow.models.interfaces.tunable": [[15, 2, 1, "", "Tunable"]], "lmflow.models.regression_model": [[16, 2, 1, "", "RegressionModel"]], "lmflow.models.text_regression_model": [[17, 2, 1, "", "TextRegressionModel"]], "lmflow.models.text_regression_model.TextRegressionModel": [[17, 3, 1, "", "get_regression"], [17, 3, 1, "", "register_regression_function"]], "lmflow.pipeline": [[18, 0, 0, "-", "auto_pipeline"], [19, 0, 0, "-", "base_aligner"], [20, 0, 0, "-", "base_pipeline"], [21, 0, 0, "-", "base_tuner"], [22, 0, 0, "-", "evaluator"], [23, 0, 0, "-", "finetuner"], [25, 0, 0, "-", "inferencer"], [26, 0, 0, "-", "raft_aligner"], [27, 0, 0, "-", "utils"]], "lmflow.pipeline.auto_pipeline": [[18, 2, 1, "", "AutoPipeline"], [18, 1, 1, "", "PIPELINE_MAPPING"]], "lmflow.pipeline.auto_pipeline.AutoPipeline": [[18, 3, 1, "", "get_pipeline"]], "lmflow.pipeline.base_aligner": [[19, 2, 1, "", "BaseAligner"]], "lmflow.pipeline.base_aligner.BaseAligner": [[19, 3, 1, "", "_check_if_alignable"], [19, 3, 1, "", "align"]], "lmflow.pipeline.base_pipeline": [[20, 2, 1, "", "BasePipeline"]], "lmflow.pipeline.base_tuner": [[21, 2, 1, "", "BaseTuner"]], "lmflow.pipeline.base_tuner.BaseTuner": [[21, 3, 1, "", "_check_if_tunable"], [21, 3, 1, "", "tune"]], "lmflow.pipeline.evaluator": [[22, 2, 1, "", "Evaluator"]], "lmflow.pipeline.evaluator.Evaluator": [[22, 3, 1, "", "_evaluate_ppl"], [22, 3, 1, "", "_match"], [22, 3, 1, "", "create_dataloader"], [22, 3, 1, "", "evaluate"]], "lmflow.pipeline.finetuner": [[23, 2, 1, "", "Finetuner"], [23, 1, 1, "", "logger"]], "lmflow.pipeline.finetuner.Finetuner": [[23, 3, 1, "", "group_text"], [23, 3, 1, "", "tune"]], "lmflow.pipeline.inferencer": [[25, 2, 1, "", "Inferencer"]], "lmflow.pipeline.inferencer.Inferencer": [[25, 3, 1, "", "create_dataloader"], [25, 3, 1, "", "inference"]], "lmflow.pipeline.raft_aligner": [[26, 2, 1, "", "RaftAligner"], [26, 1, 1, "", "logger"]], "lmflow.pipeline.raft_aligner.RaftAligner": [[26, 3, 1, "", "_get_batch_dataset_top"], [26, 3, 1, "", "_initialize_trainer"], [26, 3, 1, "", "_load_dataset"], [26, 3, 1, "", "_load_input_dataset"], [26, 3, 1, "", "align"]], "lmflow.pipeline.utils": [[28, 0, 0, "-", "raft_trainer"]], "lmflow.pipeline.utils.raft_trainer": [[28, 1, 1, "", "DEFAULT_CALLBACKS"], [28, 1, 1, "id0", "DEFAULT_PROGRESS_CALLBACK"], [28, 1, 1, "", "IS_SAGEMAKER_MP_POST_1_10"], [28, 1, 1, "", "OPTIMIZER_NAME"], [28, 2, 1, "", "RaftTrainer"], [28, 1, 1, "", "SCALER_NAME"], [28, 1, 1, "", "SCHEDULER_NAME"], [28, 1, 1, "", "TRAINER_STATE_NAME"], [28, 1, 1, "", "TRAINING_ARGS_NAME"], [28, 1, 1, "", "_is_native_cpu_amp_available"], [28, 1, 1, "", "logger"], [28, 1, 1, "", "skip_first_batches"]], "lmflow.pipeline.utils.raft_trainer.RaftTrainer": [[28, 3, 1, "", "_add_sm_patterns_to_gitignore"], [28, 3, 1, "", "_gather_and_numpify"], [28, 3, 1, "", "_get_collator_with_removed_columns"], [28, 3, 1, "", "_get_eval_sampler"], [28, 3, 1, "", "_get_output_dir"], [28, 3, 1, "", "_get_train_sampler"], [28, 3, 1, "", "_hp_search_setup"], [28, 3, 1, "", "_inner_training_loop"], [28, 3, 1, "", "_issue_warnings_after_load"], [28, 3, 1, "", "_load_best_model"], [28, 3, 1, "", "_load_from_checkpoint"], [28, 3, 1, "", "_load_optimizer_and_scheduler"], [28, 3, 1, "", "_load_rng_state"], [28, 3, 1, "", "_maybe_log_save_evaluate"], [28, 3, 1, "", "_move_model_to_device"], [28, 3, 1, "", "_nested_gather"], [28, 3, 1, "", "_one_train"], [28, 3, 1, "", "_pad_across_processes"], [28, 3, 1, "", "_prepare_input"], [28, 3, 1, "", "_prepare_inputs"], [28, 3, 1, "", "_push_from_checkpoint"], [28, 3, 1, "", "_remove_unused_columns"], [28, 3, 1, "", "_report_to_hp_search"], [28, 3, 1, "", "_rotate_checkpoints"], [28, 3, 1, "", "_save"], [28, 3, 1, "", "_save_checkpoint"], [28, 3, 1, "", "_save_tpu"], [28, 3, 1, "", "_set_signature_columns_if_needed"], [28, 3, 1, "", "_sorted_checkpoints"], [28, 3, 1, "", "_tune_save_checkpoint"], [28, 3, 1, "", "_wrap_model"], [28, 3, 1, "", "add_callback"], [28, 3, 1, "", "autocast_smart_context_manager"], [28, 3, 1, "", "call_model_init"], [28, 3, 1, "", "compute_loss"], [28, 3, 1, "", "compute_loss_context_manager"], [28, 3, 1, "", "create_model_card"], [28, 3, 1, "", "create_optimizer"], [28, 3, 1, "", "create_optimizer_and_scheduler"], [28, 3, 1, "", "create_scheduler"], [28, 3, 1, "", "evaluate"], [28, 3, 1, "", "evaluation_loop"], [28, 3, 1, "", "floating_point_ops"], [28, 3, 1, "", "get_eval_dataloader"], [28, 3, 1, "", "get_optimizer_cls_and_kwargs"], [28, 3, 1, "", "get_test_dataloader"], [28, 3, 1, "", "get_train_dataloader"], [28, 3, 1, "", "hyperparameter_search"], [28, 3, 1, "", "init_git_repo"], [28, 3, 1, "", "ipex_optimize_model"], [28, 3, 1, "", "is_local_process_zero"], [28, 3, 1, "", "is_world_process_zero"], [28, 3, 1, "", "log"], [28, 3, 1, "", "num_examples"], [28, 3, 1, "", "pop_callback"], [28, 3, 1, "", "predict"], [28, 3, 1, "", "prediction_loop"], [28, 3, 1, "", "prediction_step"], [28, 3, 1, "", "push_to_hub"], [28, 3, 1, "", "remove_callback"], [28, 3, 1, "", "save_model"], [28, 3, 1, "", "store_flos"], [28, 3, 1, "", "torch_jit_model_eval"], [28, 3, 1, "", "train"], [28, 3, 1, "", "training_step"]], "lmflow.utils": [[29, 0, 0, "-", "data_utils"]], "lmflow.utils.data_utils": [[29, 5, 1, "", "answer_extraction"], [29, 5, 1, "", "batchlize"], [29, 5, 1, "", "load_data"], [29, 5, 1, "", "set_random_seed"]], "lmflow.version": [[31, 1, 1, "", "__version__"]]}, "objtypes": {"0": "py:module", "1": "py:data", "2": "py:class", "3": "py:method", "4": "py:attribute", "5": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "data", "Python data"], "2": ["py", "class", "Python class"], "3": ["py", "method", "Python method"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "function", "Python function"]}, "titleterms": {"contributor": 0, "changelog": 1, "version": [1, 31], "0": 1, "1": 1, "mar": 1, "28": 1, "2023": 1, "about": 2, "lmflow": [3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 40], "arg": [3, 5], "api": 4, "refer": 4, "modul": [5, 6, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 28, 29, 31], "content": [5, 6, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 28, 29, 31, 40], "class": [5, 6, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 28], "attribut": [5, 6, 12, 18, 23, 26, 28], "dataset": [6, 7, 37], "submodul": [7, 8, 13, 14, 24, 27, 30], "subpackag": [8, 13, 24], "packag": 8, "model": [9, 10, 11, 12, 13, 14, 15, 16, 17, 33, 35], "auto_model": 9, "base_model": 10, "decoder_model": 11, "hf_decoder_model": 12, "interfac": [14, 15], "tunabl": 15, "regression_model": 16, "text_regression_model": 17, "pipelin": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], "auto_pipelin": 18, "base_align": 19, "base_pipelin": 20, "base_tun": 21, "evalu": 22, "finetun": [23, 38, 39], "inferenc": 25, "raft_align": 26, "util": [27, 28, 29, 30], "raft_train": 28, "data_util": 29, "function": 29, "data": [32, 33, 38], "document": 33, "prepar": [33, 38], "tune": [33, 36, 40], "infer": [33, 34, 38], "fine": 36, "format": 37, "gener": 37, "support": [37, 40], "detail": 37, "textonli": 37, "text2text": 37, "exampl": 38, "introduct": 40, "featur": 40, "task": 40, "instruct": 40, "instal": 40, "checkpoint": 40, "citat": 40, "disclaim": 40, "indic": 40, "tabl": 40}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 57}, "alltitles": {"Contributors": [[0, "contributors"]], "Changelog": [[1, "changelog"]], "Version 0.0.1 (Mar 28, 2023)": [[1, "version-0-0-1-mar-28-2023"]], "About": [[2, "about"]], "lmflow.args": [[3, "module-lmflow.args"], [5, "module-lmflow.args"]], "API Reference": [[4, "api-reference"]], "Module Contents": [[5, "module-contents"], [6, "module-contents"], [9, "module-contents"], [10, "module-contents"], [11, "module-contents"], [12, "module-contents"], [15, "module-contents"], [16, "module-contents"], [17, "module-contents"], [18, "module-contents"], [19, "module-contents"], [20, "module-contents"], [21, "module-contents"], [22, "module-contents"], [23, "module-contents"], [25, "module-contents"], [26, "module-contents"], [28, "module-contents"], [29, "module-contents"], [31, "module-contents"]], "Classes": [[5, "classes"], [6, "classes"], [9, "classes"], [10, "classes"], [11, "classes"], [12, "classes"], [15, "classes"], [16, "classes"], [17, "classes"], [18, "classes"], [19, "classes"], [20, "classes"], [21, "classes"], [22, "classes"], [23, "classes"], [25, "classes"], [26, "classes"], [28, "classes"]], "Attributes": [[5, "attributes"], [6, "attributes"], [12, "attributes"], [18, "attributes"], [23, "attributes"], [26, "attributes"], [28, "attributes"]], "lmflow.datasets.dataset": [[6, "module-lmflow.datasets.dataset"]], "lmflow.datasets": [[7, "module-lmflow.datasets"]], "Submodules": [[7, "submodules"], [8, "submodules"], [13, "submodules"], [14, "submodules"], [24, "submodules"], [27, "submodules"], [30, "submodules"]], "lmflow": [[8, "module-lmflow"]], "Subpackages": [[8, "subpackages"], [13, "subpackages"], [24, "subpackages"]], "Package Contents": [[8, "package-contents"]], "lmflow.models.auto_model": [[9, "module-lmflow.models.auto_model"]], "lmflow.models.base_model": [[10, "module-lmflow.models.base_model"]], "lmflow.models.decoder_model": [[11, "module-lmflow.models.decoder_model"]], "lmflow.models.hf_decoder_model": [[12, "module-lmflow.models.hf_decoder_model"]], "lmflow.models": [[13, "module-lmflow.models"]], "lmflow.models.interfaces": [[14, "module-lmflow.models.interfaces"]], "lmflow.models.interfaces.tunable": [[15, "module-lmflow.models.interfaces.tunable"]], "lmflow.models.regression_model": [[16, "module-lmflow.models.regression_model"]], "lmflow.models.text_regression_model": [[17, "module-lmflow.models.text_regression_model"]], "lmflow.pipeline.auto_pipeline": [[18, "module-lmflow.pipeline.auto_pipeline"]], "lmflow.pipeline.base_aligner": [[19, "module-lmflow.pipeline.base_aligner"]], "lmflow.pipeline.base_pipeline": [[20, "module-lmflow.pipeline.base_pipeline"]], "lmflow.pipeline.base_tuner": [[21, "module-lmflow.pipeline.base_tuner"]], "lmflow.pipeline.evaluator": [[22, "module-lmflow.pipeline.evaluator"]], "lmflow.pipeline.finetuner": [[23, "module-lmflow.pipeline.finetuner"]], "lmflow.pipeline": [[24, "module-lmflow.pipeline"]], "lmflow.pipeline.inferencer": [[25, "module-lmflow.pipeline.inferencer"]], "lmflow.pipeline.raft_aligner": [[26, "module-lmflow.pipeline.raft_aligner"]], "lmflow.pipeline.utils": [[27, "module-lmflow.pipeline.utils"]], "lmflow.pipeline.utils.raft_trainer": [[28, "module-lmflow.pipeline.utils.raft_trainer"]], "lmflow.utils.data_utils": [[29, "module-lmflow.utils.data_utils"]], "Functions": [[29, "functions"]], "lmflow.utils": [[30, "module-lmflow.utils"]], "lmflow.version": [[31, "module-lmflow.version"]], "Data": [[32, "data"]], "Documentation": [[33, "documentation"]], "Data and Model Preparation": [[33, "data-and-model-preparation"]], "Model Tuning": [[33, "model-tuning"]], "Model Inference": [[33, "model-inference"]], "Inference": [[34, "inference"], [38, "inference"]], "Model": [[35, "model"]], "Fine-tuning": [[36, "fine-tuning"]], "Dataset": [[37, "dataset"]], "Dataset Format in General": [[37, "dataset-format-in-general"]], "Supported Dataset and Detailed Formats": [[37, "supported-dataset-and-detailed-formats"]], "TextOnly": [[37, "textonly"]], "Text2Text": [[37, "text2text"]], "Examples": [[38, "examples"]], "Data preparation": [[38, "data-preparation"]], "Finetuning": [[38, "finetuning"]], "Finetune": [[39, "finetune"]], "LMFlow": [[40, "lmflow"]], "Introduction": [[40, "introduction"]], "Features": [[40, "features"]], "Task Tuning": [[40, "task-tuning"]], "Instruction Tuning": [[40, "instruction-tuning"]], "Installation": [[40, "installation"]], "Checkpoints": [[40, "checkpoints"]], "Content": [[40, "content"]], "Citation": [[40, "citation"]], "Disclaimer": [[40, "disclaimer"]], "Support": [[40, "support"]], "Indices and tables": [[40, "indices-and-tables"]]}, "indexentries": {"lmflow.args": [[3, "module-lmflow.args"], [5, "module-lmflow.args"]], "module": [[3, "module-lmflow.args"], [5, "module-lmflow.args"], [6, "module-lmflow.datasets.dataset"], [7, "module-lmflow.datasets"], [8, "module-lmflow"], [9, "module-lmflow.models.auto_model"], [10, "module-lmflow.models.base_model"], [11, "module-lmflow.models.decoder_model"], [12, "module-lmflow.models.hf_decoder_model"], [13, "module-lmflow.models"], [14, "module-lmflow.models.interfaces"], [15, "module-lmflow.models.interfaces.tunable"], [16, "module-lmflow.models.regression_model"], [17, "module-lmflow.models.text_regression_model"], [18, "module-lmflow.pipeline.auto_pipeline"], [19, "module-lmflow.pipeline.base_aligner"], [20, "module-lmflow.pipeline.base_pipeline"], [21, "module-lmflow.pipeline.base_tuner"], [22, "module-lmflow.pipeline.evaluator"], [23, "module-lmflow.pipeline.finetuner"], [24, "module-lmflow.pipeline"], [25, "module-lmflow.pipeline.inferencer"], [26, "module-lmflow.pipeline.raft_aligner"], [27, "module-lmflow.pipeline.utils"], [28, "module-lmflow.pipeline.utils.raft_trainer"], [29, "module-lmflow.utils.data_utils"], [30, "module-lmflow.utils"], [31, "module-lmflow.version"]], "autoarguments (class in lmflow.args)": [[5, "lmflow.args.AutoArguments"]], "datasetarguments (class in lmflow.args)": [[5, "lmflow.args.DatasetArguments"]], "evaluatorarguments (class in lmflow.args)": [[5, "lmflow.args.EvaluatorArguments"]], "finetunerarguments (class in lmflow.args)": [[5, "lmflow.args.FinetunerArguments"]], "inferencerarguments (class in lmflow.args)": [[5, "lmflow.args.InferencerArguments"]], "model_config_classes (in module lmflow.args)": [[5, "lmflow.args.MODEL_CONFIG_CLASSES"]], "model_types (in module lmflow.args)": [[5, "lmflow.args.MODEL_TYPES"]], "modelarguments (class in lmflow.args)": [[5, "lmflow.args.ModelArguments"]], "pipeline_argument_mapping (in module lmflow.args)": [[5, "lmflow.args.PIPELINE_ARGUMENT_MAPPING"]], "raftalignerarguments (class in lmflow.args)": [[5, "lmflow.args.RaftAlignerArguments"]], "__post_init__() (lmflow.args.datasetarguments method)": [[5, "lmflow.args.DatasetArguments.__post_init__"]], "__post_init__() (lmflow.args.modelarguments method)": [[5, "lmflow.args.ModelArguments.__post_init__"]], "answer_type (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.answer_type"]], "arch_type (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.arch_type"]], "block_size (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.block_size"]], "cache_dir (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.cache_dir"]], "config_name (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.config_name"]], "config_overrides (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.config_overrides"]], "customized_cache_dir (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.customized_cache_dir"]], "dataset_config_name (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.dataset_config_name"]], "dataset_name (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.dataset_name"]], "dataset_path (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.dataset_path"]], "deepspeed (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.deepspeed"]], "deepspeed (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.deepspeed"]], "device (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.device"]], "disable_group_texts (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.disable_group_texts"]], "evaluate_block_size (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.evaluate_block_size"]], "get_pipeline_args_class() (lmflow.args.autoarguments method)": [[5, "lmflow.args.AutoArguments.get_pipeline_args_class"]], "inference_batch_size_per_device (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.inference_batch_size_per_device"]], "is_custom_dataset (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.is_custom_dataset"]], "keep_linebreaks (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.keep_linebreaks"]], "local_rank (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.local_rank"]], "local_rank (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.local_rank"]], "lora_alpha (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.lora_alpha"]], "lora_dropout (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.lora_dropout"]], "lora_model_path (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.lora_model_path"]], "lora_r (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.lora_r"]], "max_eval_samples (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.max_eval_samples"]], "max_train_samples (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.max_train_samples"]], "metric (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.metric"]], "mixed_precision (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.mixed_precision"]], "mixed_precision (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.mixed_precision"]], "model_name_or_path (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.model_name_or_path"]], "model_revision (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.model_revision"]], "model_type (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.model_type"]], "num_raft_iteration (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.num_raft_iteration"]], "output_dir (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.output_dir"]], "output_max_length (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.output_max_length"]], "output_min_length (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.output_min_length"]], "output_reward_path (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.output_reward_path"]], "overwrite_cache (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.overwrite_cache"]], "preprocessing_num_workers (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.preprocessing_num_workers"]], "prompt_structure (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.prompt_structure"]], "raft_batch_size (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.raft_batch_size"]], "random_seed (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.random_seed"]], "random_seed (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.random_seed"]], "random_shuffle (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.random_shuffle"]], "save_aggregated_lora (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.save_aggregated_lora"]], "streaming (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.streaming"]], "test_file (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.test_file"]], "tokenizer_name (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.tokenizer_name"]], "top_reward_percentage (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.top_reward_percentage"]], "torch_dtype (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.torch_dtype"]], "train_file (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.train_file"]], "use_auth_token (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.use_auth_token"]], "use_fast_tokenizer (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.use_fast_tokenizer"]], "use_lora (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.use_lora"]], "use_ram_optimized_load (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.use_ram_optimized_load"]], "use_wandb (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.use_wandb"]], "validation_file (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.validation_file"]], "validation_split_percentage (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.validation_split_percentage"]], "dataset_types (in module lmflow.datasets.dataset)": [[6, "lmflow.datasets.dataset.DATASET_TYPES"]], "dataset (class in lmflow.datasets.dataset)": [[6, "lmflow.datasets.dataset.Dataset"]], "key_instances (in module lmflow.datasets.dataset)": [[6, "lmflow.datasets.dataset.KEY_INSTANCES"]], "key_type (in module lmflow.datasets.dataset)": [[6, "lmflow.datasets.dataset.KEY_TYPE"]], "_check_data_type() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset._check_data_type"]], "create_from_dict() (lmflow.datasets.dataset.dataset class method)": [[6, "lmflow.datasets.dataset.Dataset.create_from_dict"]], "from_dict() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.from_dict"]], "get_backend() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.get_backend"]], "get_backend_dataset() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.get_backend_dataset"]], "get_data_args() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.get_data_args"]], "get_type() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.get_type"]], "lmflow.datasets.dataset": [[6, "module-lmflow.datasets.dataset"]], "map() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.map"]], "to_dict() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.to_dict"]], "lmflow.datasets": [[7, "module-lmflow.datasets"]], "__version__ (in module lmflow)": [[8, "lmflow.__version__"]], "internal_version (in module lmflow)": [[8, "lmflow.internal_version"]], "lmflow": [[8, "module-lmflow"]], "automodel (class in lmflow.models.auto_model)": [[9, "lmflow.models.auto_model.AutoModel"]], "get_model() (lmflow.models.auto_model.automodel class method)": [[9, "lmflow.models.auto_model.AutoModel.get_model"]], "lmflow.models.auto_model": [[9, "module-lmflow.models.auto_model"]], "basemodel (class in lmflow.models.base_model)": [[10, "lmflow.models.base_model.BaseModel"]], "lmflow.models.base_model": [[10, "module-lmflow.models.base_model"]], "decodermodel (class in lmflow.models.decoder_model)": [[11, "lmflow.models.decoder_model.DecoderModel"]], "lmflow.models.decoder_model": [[11, "module-lmflow.models.decoder_model"]], "hfdecodermodel (class in lmflow.models.hf_decoder_model)": [[12, "lmflow.models.hf_decoder_model.HFDecoderModel"]], "decode() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[12, "lmflow.models.hf_decoder_model.HFDecoderModel.decode"]], "encode() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[12, "lmflow.models.hf_decoder_model.HFDecoderModel.encode"]], "get_backend_model() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[12, "lmflow.models.hf_decoder_model.HFDecoderModel.get_backend_model"]], "get_max_length() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[12, "lmflow.models.hf_decoder_model.HFDecoderModel.get_max_length"]], "get_tokenizer() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[12, "lmflow.models.hf_decoder_model.HFDecoderModel.get_tokenizer"]], "inference() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[12, "lmflow.models.hf_decoder_model.HFDecoderModel.inference"]], "lmflow.models.hf_decoder_model": [[12, "module-lmflow.models.hf_decoder_model"]], "logger (in module lmflow.models.hf_decoder_model)": [[12, "lmflow.models.hf_decoder_model.logger"]], "merge_lora_weights() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[12, "lmflow.models.hf_decoder_model.HFDecoderModel.merge_lora_weights"]], "save() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[12, "lmflow.models.hf_decoder_model.HFDecoderModel.save"]], "tokenize() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[12, "lmflow.models.hf_decoder_model.HFDecoderModel.tokenize"]], "lmflow.models": [[13, "module-lmflow.models"]], "lmflow.models.interfaces": [[14, "module-lmflow.models.interfaces"]], "tunable (class in lmflow.models.interfaces.tunable)": [[15, "lmflow.models.interfaces.tunable.Tunable"]], "lmflow.models.interfaces.tunable": [[15, "module-lmflow.models.interfaces.tunable"]], "regressionmodel (class in lmflow.models.regression_model)": [[16, "lmflow.models.regression_model.RegressionModel"]], "lmflow.models.regression_model": [[16, "module-lmflow.models.regression_model"]], "textregressionmodel (class in lmflow.models.text_regression_model)": [[17, "lmflow.models.text_regression_model.TextRegressionModel"]], "get_regression() (lmflow.models.text_regression_model.textregressionmodel method)": [[17, "lmflow.models.text_regression_model.TextRegressionModel.get_regression"]], "lmflow.models.text_regression_model": [[17, "module-lmflow.models.text_regression_model"]], "register_regression_function() (lmflow.models.text_regression_model.textregressionmodel method)": [[17, "lmflow.models.text_regression_model.TextRegressionModel.register_regression_function"]], "autopipeline (class in lmflow.pipeline.auto_pipeline)": [[18, "lmflow.pipeline.auto_pipeline.AutoPipeline"]], "pipeline_mapping (in module lmflow.pipeline.auto_pipeline)": [[18, "lmflow.pipeline.auto_pipeline.PIPELINE_MAPPING"]], "get_pipeline() (lmflow.pipeline.auto_pipeline.autopipeline class method)": [[18, "lmflow.pipeline.auto_pipeline.AutoPipeline.get_pipeline"]], "lmflow.pipeline.auto_pipeline": [[18, "module-lmflow.pipeline.auto_pipeline"]], "basealigner (class in lmflow.pipeline.base_aligner)": [[19, "lmflow.pipeline.base_aligner.BaseAligner"]], "_check_if_alignable() (lmflow.pipeline.base_aligner.basealigner method)": [[19, "lmflow.pipeline.base_aligner.BaseAligner._check_if_alignable"]], "align() (lmflow.pipeline.base_aligner.basealigner method)": [[19, "lmflow.pipeline.base_aligner.BaseAligner.align"]], "lmflow.pipeline.base_aligner": [[19, "module-lmflow.pipeline.base_aligner"]], "basepipeline (class in lmflow.pipeline.base_pipeline)": [[20, "lmflow.pipeline.base_pipeline.BasePipeline"]], "lmflow.pipeline.base_pipeline": [[20, "module-lmflow.pipeline.base_pipeline"]], "basetuner (class in lmflow.pipeline.base_tuner)": [[21, "lmflow.pipeline.base_tuner.BaseTuner"]], "_check_if_tunable() (lmflow.pipeline.base_tuner.basetuner method)": [[21, "lmflow.pipeline.base_tuner.BaseTuner._check_if_tunable"]], "lmflow.pipeline.base_tuner": [[21, "module-lmflow.pipeline.base_tuner"]], "tune() (lmflow.pipeline.base_tuner.basetuner method)": [[21, "lmflow.pipeline.base_tuner.BaseTuner.tune"]], "evaluator (class in lmflow.pipeline.evaluator)": [[22, "lmflow.pipeline.evaluator.Evaluator"]], "_evaluate_ppl() (lmflow.pipeline.evaluator.evaluator method)": [[22, "lmflow.pipeline.evaluator.Evaluator._evaluate_ppl"]], "_match() (lmflow.pipeline.evaluator.evaluator method)": [[22, "lmflow.pipeline.evaluator.Evaluator._match"]], "create_dataloader() (lmflow.pipeline.evaluator.evaluator method)": [[22, "lmflow.pipeline.evaluator.Evaluator.create_dataloader"]], "evaluate() (lmflow.pipeline.evaluator.evaluator method)": [[22, "lmflow.pipeline.evaluator.Evaluator.evaluate"]], "lmflow.pipeline.evaluator": [[22, "module-lmflow.pipeline.evaluator"]], "finetuner (class in lmflow.pipeline.finetuner)": [[23, "lmflow.pipeline.finetuner.Finetuner"]], "group_text() (lmflow.pipeline.finetuner.finetuner method)": [[23, "lmflow.pipeline.finetuner.Finetuner.group_text"]], "lmflow.pipeline.finetuner": [[23, "module-lmflow.pipeline.finetuner"]], "logger (in module lmflow.pipeline.finetuner)": [[23, "lmflow.pipeline.finetuner.logger"]], "tune() (lmflow.pipeline.finetuner.finetuner method)": [[23, "lmflow.pipeline.finetuner.Finetuner.tune"]], "lmflow.pipeline": [[24, "module-lmflow.pipeline"]], "inferencer (class in lmflow.pipeline.inferencer)": [[25, "lmflow.pipeline.inferencer.Inferencer"]], "create_dataloader() (lmflow.pipeline.inferencer.inferencer method)": [[25, "lmflow.pipeline.inferencer.Inferencer.create_dataloader"]], "inference() (lmflow.pipeline.inferencer.inferencer method)": [[25, "lmflow.pipeline.inferencer.Inferencer.inference"]], "lmflow.pipeline.inferencer": [[25, "module-lmflow.pipeline.inferencer"]], "raftaligner (class in lmflow.pipeline.raft_aligner)": [[26, "lmflow.pipeline.raft_aligner.RaftAligner"]], "_get_batch_dataset_top() (lmflow.pipeline.raft_aligner.raftaligner method)": [[26, "lmflow.pipeline.raft_aligner.RaftAligner._get_batch_dataset_top"]], "_initialize_trainer() (lmflow.pipeline.raft_aligner.raftaligner method)": [[26, "lmflow.pipeline.raft_aligner.RaftAligner._initialize_trainer"]], "_load_dataset() (lmflow.pipeline.raft_aligner.raftaligner method)": [[26, "lmflow.pipeline.raft_aligner.RaftAligner._load_dataset"]], "_load_input_dataset() (lmflow.pipeline.raft_aligner.raftaligner method)": [[26, "lmflow.pipeline.raft_aligner.RaftAligner._load_input_dataset"]], "align() (lmflow.pipeline.raft_aligner.raftaligner method)": [[26, "lmflow.pipeline.raft_aligner.RaftAligner.align"]], "lmflow.pipeline.raft_aligner": [[26, "module-lmflow.pipeline.raft_aligner"]], "logger (in module lmflow.pipeline.raft_aligner)": [[26, "lmflow.pipeline.raft_aligner.logger"]], "lmflow.pipeline.utils": [[27, "module-lmflow.pipeline.utils"]], "default_callbacks (in module lmflow.pipeline.utils.raft_trainer)": [[28, "lmflow.pipeline.utils.raft_trainer.DEFAULT_CALLBACKS"]], "default_progress_callback (in module lmflow.pipeline.utils.raft_trainer)": [[28, "id0"], [28, "lmflow.pipeline.utils.raft_trainer.DEFAULT_PROGRESS_CALLBACK"]], "is_sagemaker_mp_post_1_10 (in module lmflow.pipeline.utils.raft_trainer)": [[28, "lmflow.pipeline.utils.raft_trainer.IS_SAGEMAKER_MP_POST_1_10"]], "optimizer_name (in module lmflow.pipeline.utils.raft_trainer)": [[28, "lmflow.pipeline.utils.raft_trainer.OPTIMIZER_NAME"]], "rafttrainer (class in lmflow.pipeline.utils.raft_trainer)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer"]], "scaler_name (in module lmflow.pipeline.utils.raft_trainer)": [[28, "lmflow.pipeline.utils.raft_trainer.SCALER_NAME"]], "scheduler_name (in module lmflow.pipeline.utils.raft_trainer)": [[28, "lmflow.pipeline.utils.raft_trainer.SCHEDULER_NAME"]], "trainer_state_name (in module lmflow.pipeline.utils.raft_trainer)": [[28, "lmflow.pipeline.utils.raft_trainer.TRAINER_STATE_NAME"]], "training_args_name (in module lmflow.pipeline.utils.raft_trainer)": [[28, "lmflow.pipeline.utils.raft_trainer.TRAINING_ARGS_NAME"]], "_add_sm_patterns_to_gitignore() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._add_sm_patterns_to_gitignore"]], "_gather_and_numpify() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._gather_and_numpify"]], "_get_collator_with_removed_columns() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._get_collator_with_removed_columns"]], "_get_eval_sampler() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._get_eval_sampler"]], "_get_output_dir() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._get_output_dir"]], "_get_train_sampler() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._get_train_sampler"]], "_hp_search_setup() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._hp_search_setup"]], "_inner_training_loop() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._inner_training_loop"]], "_is_native_cpu_amp_available (in module lmflow.pipeline.utils.raft_trainer)": [[28, "lmflow.pipeline.utils.raft_trainer._is_native_cpu_amp_available"]], "_issue_warnings_after_load() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._issue_warnings_after_load"]], "_load_best_model() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._load_best_model"]], "_load_from_checkpoint() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._load_from_checkpoint"]], "_load_optimizer_and_scheduler() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._load_optimizer_and_scheduler"]], "_load_rng_state() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._load_rng_state"]], "_maybe_log_save_evaluate() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._maybe_log_save_evaluate"]], "_move_model_to_device() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._move_model_to_device"]], "_nested_gather() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._nested_gather"]], "_one_train() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._one_train"]], "_pad_across_processes() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._pad_across_processes"]], "_prepare_input() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._prepare_input"]], "_prepare_inputs() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._prepare_inputs"]], "_push_from_checkpoint() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._push_from_checkpoint"]], "_remove_unused_columns() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._remove_unused_columns"]], "_report_to_hp_search() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._report_to_hp_search"]], "_rotate_checkpoints() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._rotate_checkpoints"]], "_save() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._save"]], "_save_checkpoint() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._save_checkpoint"]], "_save_tpu() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._save_tpu"]], "_set_signature_columns_if_needed() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._set_signature_columns_if_needed"]], "_sorted_checkpoints() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._sorted_checkpoints"]], "_tune_save_checkpoint() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._tune_save_checkpoint"]], "_wrap_model() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._wrap_model"]], "add_callback() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.add_callback"]], "autocast_smart_context_manager() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.autocast_smart_context_manager"]], "call_model_init() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.call_model_init"]], "compute_loss() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.compute_loss"]], "compute_loss_context_manager() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.compute_loss_context_manager"]], "create_model_card() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.create_model_card"]], "create_optimizer() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.create_optimizer"]], "create_optimizer_and_scheduler() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.create_optimizer_and_scheduler"]], "create_scheduler() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.create_scheduler"]], "evaluate() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.evaluate"]], "evaluation_loop() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.evaluation_loop"]], "floating_point_ops() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.floating_point_ops"]], "get_eval_dataloader() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.get_eval_dataloader"]], "get_optimizer_cls_and_kwargs() (lmflow.pipeline.utils.raft_trainer.rafttrainer static method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.get_optimizer_cls_and_kwargs"]], "get_test_dataloader() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.get_test_dataloader"]], "get_train_dataloader() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.get_train_dataloader"]], "hyperparameter_search() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.hyperparameter_search"]], "init_git_repo() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.init_git_repo"]], "ipex_optimize_model() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.ipex_optimize_model"]], "is_local_process_zero() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.is_local_process_zero"]], "is_world_process_zero() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.is_world_process_zero"]], "lmflow.pipeline.utils.raft_trainer": [[28, "module-lmflow.pipeline.utils.raft_trainer"]], "log() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.log"]], "logger (in module lmflow.pipeline.utils.raft_trainer)": [[28, "lmflow.pipeline.utils.raft_trainer.logger"]], "num_examples() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.num_examples"]], "pop_callback() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.pop_callback"]], "predict() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.predict"]], "prediction_loop() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.prediction_loop"]], "prediction_step() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.prediction_step"]], "push_to_hub() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.push_to_hub"]], "remove_callback() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.remove_callback"]], "save_model() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.save_model"]], "skip_first_batches (in module lmflow.pipeline.utils.raft_trainer)": [[28, "lmflow.pipeline.utils.raft_trainer.skip_first_batches"]], "store_flos() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.store_flos"]], "torch_jit_model_eval() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.torch_jit_model_eval"]], "train() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.train"]], "training_step() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[28, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.training_step"]], "answer_extraction() (in module lmflow.utils.data_utils)": [[29, "lmflow.utils.data_utils.answer_extraction"]], "batchlize() (in module lmflow.utils.data_utils)": [[29, "lmflow.utils.data_utils.batchlize"]], "lmflow.utils.data_utils": [[29, "module-lmflow.utils.data_utils"]], "load_data() (in module lmflow.utils.data_utils)": [[29, "lmflow.utils.data_utils.load_data"]], "set_random_seed() (in module lmflow.utils.data_utils)": [[29, "lmflow.utils.data_utils.set_random_seed"]], "lmflow.utils": [[30, "module-lmflow.utils"]], "__version__ (in module lmflow.version)": [[31, "lmflow.version.__version__"]], "lmflow.version": [[31, "module-lmflow.version"]]}})